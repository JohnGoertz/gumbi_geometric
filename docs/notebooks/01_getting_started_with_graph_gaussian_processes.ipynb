{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from vsup import VSUP\n",
    "\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import botorch\n",
    "import geometric_kernels as gk\n",
    "import geometric_kernels.torch\n",
    "import gpytorch\n",
    "import numpy as np\n",
    "import torch\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.models.transforms.input import Normalize as NormalizeInput\n",
    "from botorch.models.transforms.outcome import Standardize as StandardizeOutput\n",
    "from geometric_kernels.frontends.gpytorch import GPyTorchGeometricKernel\n",
    "from geometric_kernels.kernels import MaternGeometricKernel\n",
    "from geometric_kernels.spaces import Graph\n",
    "from gpytorch.likelihoods.gaussian_likelihood import GaussianLikelihood\n",
    "from gpytorch.priors.torch_priors import GammaPrior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_plot(\n",
    "    G,\n",
    "    attribute=None,\n",
    "    uncertainty=None,\n",
    "    *,\n",
    "    label=False,\n",
    "    cmap=None,\n",
    "    vmin=None,\n",
    "    vmax=None,\n",
    "    umin=None,\n",
    "    umax=None,\n",
    "    quantization=\"linear\",\n",
    "    ax=None,\n",
    "    figsize=(6, 4),\n",
    "    pos=None,\n",
    "    node_size=200,\n",
    "    **kwargs,\n",
    "):\n",
    "    G = G.copy()  # Ensure we don't modify the original graph\n",
    "\n",
    "    attributes = nx.get_node_attributes(G, attribute)\n",
    "    if vmin is None:\n",
    "        vmin = min(attributes.values())\n",
    "    if vmax is None:\n",
    "        vmax = max(attributes.values())\n",
    "    # norm = Normalize(vmin=vmin, vmax=vmax)\n",
    "\n",
    "    if uncertainty is not None:\n",
    "        uncertainties = nx.get_node_attributes(G, uncertainty)\n",
    "        assert uncertainties.keys() == attributes.keys(), (\n",
    "            \"All nodes with either attribute and uncertainty values must have both.\"\n",
    "        )\n",
    "        if umin is None:\n",
    "            umin = min(uncertainties.values())\n",
    "        if umax is None:\n",
    "            umax = max(uncertainties.values())\n",
    "    else:\n",
    "        uncertainties = {node: 0 for node in attributes.keys()}\n",
    "        umin = 0\n",
    "        umax = 1\n",
    "        quantization = None\n",
    "    labeled_nodes = attributes.keys() if attribute is not None else []\n",
    "    node_vu = {node: (attributes[node], uncertainties[node]) for node in labeled_nodes}\n",
    "\n",
    "    # Prepare color map\n",
    "    if cmap is None:\n",
    "        cmap = sns.diverging_palette(220, 20, center=\"dark\", as_cmap=True)\n",
    "    elif isinstance(cmap, str):\n",
    "        cmap = sns.color_palette(cmap, as_cmap=True)\n",
    "    # Prepare Value-Supressing Uncertainty Palette (VSUP)\n",
    "    vsup = VSUP(\n",
    "        palette=cmap,\n",
    "        vmin=vmin,\n",
    "        vmax=vmax,\n",
    "        umin=umin,\n",
    "        umax=umax,\n",
    "        quantization=quantization,\n",
    "    )\n",
    "\n",
    "    node_edgecolors = [\"black\"] * len(G.nodes)\n",
    "    # If node_attr is None, color all nodes white\n",
    "    if attribute is None:\n",
    "        node_colors = [\"white\"] * len(G.nodes)\n",
    "    else:\n",
    "        node_colors = []\n",
    "        for node in G.nodes:\n",
    "            if node in labeled_nodes:\n",
    "                value, uncertainty = node_vu[node]\n",
    "                color = vsup(value, uncertainty)\n",
    "                node_colors.append(color)\n",
    "                node_edgecolors.append(\"black\")\n",
    "            else:\n",
    "                node_colors.append(\"white\")\n",
    "                node_edgecolors.append(\"black\")\n",
    "\n",
    "    if pos is None:\n",
    "        # Get positions so that (i, j) is at (j, -i) for grid-like display\n",
    "        pos = {n: (n[1], -n[0]) for n in G.nodes}\n",
    "\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=figsize)\n",
    "    else:\n",
    "        fig = ax.figure\n",
    "    nx.draw(\n",
    "        G,\n",
    "        pos=pos,\n",
    "        node_color=node_colors,\n",
    "        edgecolors=node_edgecolors,\n",
    "        with_labels=False,\n",
    "        node_size=node_size,\n",
    "        ax=ax,\n",
    "        **kwargs,\n",
    "    )\n",
    "    # Optionally, mark the valued nodes with their value\n",
    "    if label and attribute is not None:\n",
    "        for node in G.nodes:\n",
    "            if attribute in G.nodes[node]:\n",
    "                val = G.nodes[node][attribute]\n",
    "                ax.text(\n",
    "                    pos[node][0],\n",
    "                    pos[node][1],\n",
    "                    str(val),\n",
    "                    color=\"black\",\n",
    "                    ha=\"center\",\n",
    "                    va=\"center\",\n",
    "                    fontsize=10,\n",
    "                    fontweight=\"bold\",\n",
    "                )\n",
    "    return vsup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to ensure reproducibility\n",
    "def set_seeds(seed=42):\n",
    "    \"\"\"Sets random seeds for reproducibility.\"\"\"\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "\n",
    "# Set seeds for consistent results\n",
    "set_seeds()\n",
    "\n",
    "\n",
    "# Define the Gaussian Process model on the graph\n",
    "class GraphGP:\n",
    "    \"\"\"\n",
    "    A GPyTorch model for Graph Gaussian Processes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        graph,\n",
    "        attribute,\n",
    "        normalize_laplacian=False,\n",
    "        trainable_nu=False,\n",
    "        nu=0.5,\n",
    "        scale_prior=(2.0, 0.15),\n",
    "        noise_prior=(1.1, 0.05),\n",
    "        noise_min=1e-8,\n",
    "    ):\n",
    "        graph_torch = torch.tensor(nx.to_numpy_array(graph))\n",
    "        graph_space = Graph(graph_torch, normalize_laplacian=normalize_laplacian)\n",
    "        mean_module = gpytorch.means.ConstantMean()\n",
    "\n",
    "        geo_kernel = MaternGeometricKernel(graph_space, nu=nu)\n",
    "        params = geo_kernel.init_params()\n",
    "        params[\"nu\"] = torch.tensor([nu], dtype=torch.float64)\n",
    "        params[\"lengthscale\"] = torch.tensor(params[\"lengthscale\"], dtype=torch.float64)\n",
    "        base_kernel = GPyTorchGeometricKernel(\n",
    "            geo_kernel,\n",
    "            nu=params[\"nu\"],\n",
    "            trainable_nu=trainable_nu,\n",
    "            lengthscale=params[\"lengthscale\"],\n",
    "            # lengthscale_prior=GammaPrior(3.0, 6.0),\n",
    "        )\n",
    "        covar_module = gpytorch.kernels.ScaleKernel(\n",
    "            base_kernel,\n",
    "            outputscale_prior=GammaPrior(*scale_prior),\n",
    "        )\n",
    "\n",
    "        noise_prior = GammaPrior(*noise_prior)\n",
    "        noise_prior_mode = (noise_prior.concentration - 1) / noise_prior.rate\n",
    "        lik = GaussianLikelihood(\n",
    "            noise_prior=noise_prior,\n",
    "            noise_constraint=gpytorch.constraints.GreaterThan(noise_min),\n",
    "            initial_value=noise_prior_mode,\n",
    "        )\n",
    "\n",
    "        node_index = {node: list(graph.nodes).index(node) for node in graph.nodes}\n",
    "        attr_dict = nx.get_node_attributes(graph, attribute)\n",
    "        # Prepare training data\n",
    "        train_x, train_y = torch.tensor(\n",
    "            [[node_index[node], val] for node, val in attr_dict.items()], dtype=float\n",
    "        ).T\n",
    "\n",
    "        self.model = SingleTaskGP(\n",
    "            train_x[:, None],\n",
    "            train_y[:, None],\n",
    "            mean_module=mean_module,\n",
    "            covar_module=covar_module,\n",
    "            likelihood=lik,\n",
    "            # input_transform=NormalizeInput(d=1),\n",
    "            # outcome_transform=StandardizeOutput(m=1),\n",
    "        )\n",
    "        self.mll = gpytorch.mlls.ExactMarginalLogLikelihood(\n",
    "            self.model.likelihood, self.model\n",
    "        )\n",
    "\n",
    "    def fit(self):\n",
    "        return fit_gpytorch_mll(mll=self.mll)\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        graph,\n",
    "        store_pred_as=\"prediction\",\n",
    "        mean_name=\"mean\",\n",
    "        var_name=\"var\",\n",
    "        std_name=\"std\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Predicts the values of the attribute for all nodes in the graph.\n",
    "        \"\"\"\n",
    "        # Ensure the model is in evaluation mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # Prepare input for prediction\n",
    "        all_nodes = torch.arange(graph.number_of_nodes()).long()[:, None]\n",
    "        idx2node = {idx: node for idx, node in enumerate(graph.nodes)}\n",
    "\n",
    "        store_pred = store_pred_as is not None\n",
    "        if store_pred is False:\n",
    "            store_pred_as = \"prediction\"\n",
    "        # Convert predictions to a dictionary\n",
    "        posterior = self.model.posterior(all_nodes)\n",
    "        node_posteriors = {\n",
    "            idx2node[idx]: {\n",
    "                f\"{store_pred_as}_{mean_name}\": mn.item(),\n",
    "                f\"{store_pred_as}_{var_name}\": vr.item(),\n",
    "                f\"{store_pred_as}_{std_name}\": float(np.sqrt(vr.item())),\n",
    "            }\n",
    "            for idx, (mn, vr) in enumerate(zip(posterior.mean, posterior.variance))\n",
    "        }\n",
    "\n",
    "        if store_pred:\n",
    "            # Store predictions as node attributes in the graph\n",
    "            nx.set_node_attributes(graph, node_posteriors)\n",
    "\n",
    "        return node_posteriors\n",
    "\n",
    "\n",
    "class SpatialGP:\n",
    "    \"\"\"\n",
    "    A GPyTorch model for standard (Euclidean) Gaussian Processes using node coordinates as inputs.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        graph,\n",
    "        attribute,\n",
    "        nu=0.5,\n",
    "        scale_prior=(2.0, 0.15),\n",
    "        noise_prior=(1.1, 0.05),\n",
    "        noise_min=1e-8,\n",
    "        normalize_laplacian=None,\n",
    "    ):\n",
    "        # Extract node coordinates (assume node names are (x1, x2) tuples)\n",
    "        attr_dict = nx.get_node_attributes(graph, attribute)\n",
    "        X = torch.tensor([list(node) for node in attr_dict.keys()], dtype=torch.float64)\n",
    "        y = torch.tensor([val for val in attr_dict.values()], dtype=torch.float64)\n",
    "\n",
    "        mean_module = gpytorch.means.ConstantMean()\n",
    "        if nu == np.inf:\n",
    "            base_kernel = gpytorch.kernels.ScaleKernel(\n",
    "                gpytorch.kernels.RBFKernel(lengthscale_prior=GammaPrior(3.0, 6.0)),\n",
    "                outputscale_prior=GammaPrior(*scale_prior),\n",
    "            )\n",
    "        else:\n",
    "            base_kernel = gpytorch.kernels.ScaleKernel(\n",
    "                gpytorch.kernels.MaternKernel(\n",
    "                    nu=nu, lengthscale_prior=GammaPrior(3.0, 6.0)\n",
    "                ),\n",
    "                outputscale_prior=GammaPrior(*scale_prior),\n",
    "            )\n",
    "\n",
    "        noise_prior_obj = GammaPrior(*noise_prior)\n",
    "        noise_prior_mode = (noise_prior_obj.concentration - 1) / noise_prior_obj.rate\n",
    "        lik = GaussianLikelihood(\n",
    "            noise_prior=noise_prior_obj,\n",
    "            noise_constraint=gpytorch.constraints.GreaterThan(noise_min),\n",
    "            initial_value=noise_prior_mode,\n",
    "        )\n",
    "\n",
    "        self.model = SingleTaskGP(\n",
    "            X,\n",
    "            y[:, None],\n",
    "            mean_module=mean_module,\n",
    "            covar_module=base_kernel,\n",
    "            likelihood=lik,\n",
    "            input_transform=NormalizeInput(d=X.shape[1]),\n",
    "            outcome_transform=StandardizeOutput(m=1),\n",
    "        )\n",
    "        self.mll = gpytorch.mlls.ExactMarginalLogLikelihood(\n",
    "            self.model.likelihood, self.model\n",
    "        )\n",
    "\n",
    "    def fit(self):\n",
    "        return fit_gpytorch_mll(mll=self.mll)\n",
    "\n",
    "    def predict(\n",
    "        self,\n",
    "        graph,\n",
    "        store_pred_as=\"prediction\",\n",
    "        mean_name=\"mean\",\n",
    "        var_name=\"var\",\n",
    "        std_name=\"std\",\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Predicts the values of the attribute for all nodes in the graph using their coordinates.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        all_coords = torch.tensor(\n",
    "            [list(node) for node in graph.nodes], dtype=torch.float\n",
    "        )\n",
    "        idx2node = {idx: node for idx, node in enumerate(graph.nodes)}\n",
    "\n",
    "        store_pred = store_pred_as is not None\n",
    "        if store_pred is False:\n",
    "            store_pred_as = \"prediction\"\n",
    "        # Convert predictions to a dictionary\n",
    "        posterior = self.model.posterior(all_coords)\n",
    "        node_posteriors = {\n",
    "            idx2node[idx]: {\n",
    "                f\"{store_pred_as}_{mean_name}\": mn.item(),\n",
    "                f\"{store_pred_as}_{var_name}\": vr.item(),\n",
    "                f\"{store_pred_as}_{std_name}\": float(np.sqrt(vr.item())),\n",
    "            }\n",
    "            for idx, (mn, vr) in enumerate(zip(posterior.mean, posterior.variance))\n",
    "        }\n",
    "\n",
    "        if store_pred:\n",
    "            # Store predictions as node attributes in the graph\n",
    "            nx.set_node_attributes(graph, node_posteriors)\n",
    "\n",
    "        return node_posteriors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trivial \"1D\" Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the figure\n",
    "fig, axs = plt.subplot_mosaic([[\"a\", \"b\"], [\"c\", \"b\"], [\"d\", \"b\"]], figsize=(8, 4))\n",
    "\n",
    "\n",
    "# Create a minimal graph with 11 nodes\n",
    "G1 = nx.grid_2d_graph(1, 11)\n",
    "\n",
    "# Assign values to specific nodes\n",
    "nx.set_node_attributes(\n",
    "    G1,\n",
    "    {\n",
    "        (0, 1): 1,\n",
    "        (0, 2): -1,\n",
    "        (0, 6): 2,\n",
    "        # (0, 9): -2,\n",
    "    },\n",
    "    \"observation\",\n",
    ")\n",
    "\n",
    "\n",
    "def label_graph(ax, label):\n",
    "    \"\"\"Add a Label to the left of the plotted graph.\"\"\"\n",
    "    ax.set_yticks([0])\n",
    "    ax.axis(\"on\")\n",
    "    ax.set_yticklabels([label], color=\"k\", fontsize=15)\n",
    "    ax.tick_params(axis=\"x\", which=\"both\", bottom=False, top=False, labelbottom=False)\n",
    "    ax.tick_params(axis=\"y\", which=\"both\", left=False, right=False)\n",
    "    for spine in ax.spines.values():\n",
    "        spine.set_visible(False)\n",
    "\n",
    "\n",
    "# Define the parameters for the prediction plots\n",
    "pred_plot_kwargs = {\n",
    "    \"vmin\": -2,\n",
    "    \"vmax\": +2,\n",
    "    \"umin\": 0.8,\n",
    "    \"umax\": 2.1,\n",
    "    \"hide_ticks\": False,\n",
    "}\n",
    "\n",
    "# Plot the graph with observations\n",
    "ax = axs[\"a\"]\n",
    "vsup = grid_plot(G1, \"observation\", label=True, ax=ax, **pred_plot_kwargs)\n",
    "\n",
    "label_graph(ax, \"Observation\")\n",
    "\n",
    "# Define and fit the GraphGP model\n",
    "G1_model_graph = GraphGP(\n",
    "    G1,\n",
    "    \"observation\",\n",
    "    nu=2.5,\n",
    ")\n",
    "G1_model_graph.fit()\n",
    "# Make predictions. This will also store the predictions in the graph.\n",
    "G1_model_graph.predict(G1)\n",
    "\n",
    "# Plot the mean and uncertainty of the GraphGP predictions.\n",
    "ax = axs[\"c\"]\n",
    "vsup = grid_plot(G1, \"prediction_mean\", \"prediction_std\", ax=ax, **pred_plot_kwargs)\n",
    "label_graph(ax, \"GraphGP Predictions\")\n",
    "\n",
    "# Define and fit the SpatialGP model\n",
    "G1_model_spatial = SpatialGP(\n",
    "    G1,\n",
    "    \"observation\",\n",
    "    normalize_laplacian=False,\n",
    "    nu=2.5,\n",
    "    scale_prior=(2.0, 0.15),\n",
    "    noise_prior=(1.1, 0.05),\n",
    "    noise_min=1e-8,\n",
    ")\n",
    "G1_model_spatial.fit()\n",
    "# Make predictions. This will also store the predictions in the graph.\n",
    "G1_model_spatial.predict(G1)\n",
    "\n",
    "# Plot the mean and uncertainty of the SpatialGP predictions.\n",
    "ax = axs[\"d\"]\n",
    "vsup = grid_plot(G1, \"prediction_mean\", \"prediction_std\", ax=ax, **pred_plot_kwargs)\n",
    "label_graph(ax, \"SpatialGP Predictions\")\n",
    "\n",
    "# Plot a Value-Supressing Uncertainty Palette (VSUP) arcmap legend. This is the\n",
    "# palette used for the GraphGP and SpatialGP predictions. It visualizes the\n",
    "# prediction mean via hue and uncertainty via saturation and lightness.\n",
    "ax = axs[\"b\"]\n",
    "vsup.create_arcmap_legend(ax)\n",
    "ax.set_title(\"VSUP Arcmap Legend\", fontsize=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing different nu values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize=(16, 4), sharex=True, height_ratios=[1, 1, 5])\n",
    "\n",
    "# Create a new grid graph to illustrate \"spatial\" predictions\n",
    "# This graph has nodes at (i, j/10) to simulate a continuous space\n",
    "G1_ = nx.grid_2d_graph(1, 101)\n",
    "old2new = {(i, j): (i, j / 10) for i, j in G1_.nodes}\n",
    "G1_ = nx.relabel_nodes(G1_, old2new)\n",
    "G1_model_spatial.predict(G1_)\n",
    "\n",
    "for col, nu in zip(axs.T, [0.5, 1.5, 2.5, np.inf]):\n",
    "    graph_ax = col[0]\n",
    "    if nu == np.inf:\n",
    "        graph_ax.set_title(\"nu=∞\")\n",
    "    else:\n",
    "        graph_ax.set_title(f\"nu={int(nu * 2)}/2\")\n",
    "\n",
    "    G1_model_graph = GraphGP(\n",
    "        G1,\n",
    "        \"observation\",\n",
    "        nu=nu,\n",
    "    )\n",
    "    G1_model_graph.fit()\n",
    "\n",
    "    graph_preds = G1_model_graph.predict(G1)\n",
    "    vsup = grid_plot(\n",
    "        G1, \"prediction_mean\", \"prediction_std\", ax=graph_ax, **pred_plot_kwargs\n",
    "    )\n",
    "\n",
    "    spat_grid_ax = col[1]\n",
    "    G1_model_spatial = SpatialGP(\n",
    "        G1,\n",
    "        \"observation\",\n",
    "        nu=nu,\n",
    "    )\n",
    "    G1_model_spatial.fit()\n",
    "\n",
    "    G1_model_spatial.predict(G1)\n",
    "    vsup = grid_plot(\n",
    "        G1, \"prediction_mean\", \"prediction_std\", ax=spat_grid_ax, **pred_plot_kwargs\n",
    "    )\n",
    "\n",
    "    spat_ax = col[2]\n",
    "    spat_preds = G1_model_spatial.predict(G1_)\n",
    "    spat_mean = [spat_preds[node][\"prediction_mean\"] for node in G1_.nodes]\n",
    "    spat_std = [spat_preds[node][\"prediction_std\"] for node in G1_.nodes]\n",
    "    spat_x = [node[1] for node in G1_.nodes]\n",
    "    spat_ax.plot(spat_x, spat_mean, label=\"Mean\")\n",
    "    spat_ax.fill_between(\n",
    "        spat_x,\n",
    "        np.array(spat_mean) - 2 * np.array(spat_std),\n",
    "        np.array(spat_mean) + 2 * np.array(spat_std),\n",
    "        alpha=0.2,\n",
    "        label=\"Std Dev\",\n",
    "    )\n",
    "\n",
    "    node_x, node_mean, node_std = zip(\n",
    "        *[\n",
    "            (node[1], preds[\"prediction_mean\"], preds[\"prediction_std\"])\n",
    "            for node, preds in graph_preds.items()\n",
    "        ]\n",
    "    )\n",
    "    spat_ax.errorbar(\n",
    "        node_x,\n",
    "        node_mean,\n",
    "        yerr=2 * np.array(node_std),\n",
    "        fmt=\"o\",\n",
    "        label=\"Graph GP\\nμ ± 2σ\",\n",
    "    )\n",
    "\n",
    "    obs_x, obs_y = zip(\n",
    "        *[\n",
    "            (node[1], val)\n",
    "            for node, val in nx.get_node_attributes(G1, \"observation\").items()\n",
    "        ]\n",
    "    )\n",
    "    spat_ax.scatter(obs_x, obs_y, color=\"black\", label=\"Observations\", zorder=5)\n",
    "\n",
    "# spat_ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridded \"2D\" Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(12, 4))\n",
    "\n",
    "G2 = nx.grid_2d_graph(11, 11)\n",
    "\n",
    "# Assign values to specific nodes\n",
    "nx.set_node_attributes(\n",
    "    G2,\n",
    "    {\n",
    "        (1, 2): 1,\n",
    "        (7, 7): 1,\n",
    "        (8, 1): -1,\n",
    "        (3, 7): -1,\n",
    "        (5, 4): 0,\n",
    "    },\n",
    "    \"observation\",\n",
    ")\n",
    "\n",
    "plot_kwargs_2D = {\n",
    "    \"vmin\": -1,\n",
    "    \"vmax\": 1,\n",
    "    \"umin\": 0.4,\n",
    "    \"umax\": 1.6,\n",
    "}\n",
    "\n",
    "ax = axs[0]\n",
    "vsup = grid_plot(G2, \"observation\", label=True, ax=ax, **plot_kwargs_2D)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_title(\"Observations\")\n",
    "\n",
    "G2_model_graph = GraphGP(\n",
    "    G2,\n",
    "    \"observation\",\n",
    "    nu=2.5,\n",
    ")\n",
    "G2_model_graph.fit()\n",
    "G2_model_graph.predict(G2)\n",
    "\n",
    "ax = axs[1]\n",
    "vsup = grid_plot(G2, \"prediction_mean\", \"prediction_std\", ax=ax, **plot_kwargs_2D)\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_title(\"Graph GP Predictions\")\n",
    "\n",
    "ax = axs[2]\n",
    "vsup.create_arcmap_legend(ax)\n",
    "ax.set_title(\"VSUP Arcmap Legend\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "R = np.array(\n",
    "    [\n",
    "        [np.cos(-np.pi / 4), -np.sin(-np.pi / 4)],\n",
    "        [np.sin(-np.pi / 4), np.cos(-np.pi / 4)],\n",
    "    ]\n",
    ")\n",
    "\n",
    "diamond_layout = {n: np.array([n[0], -n[1]]) @ R for n in G2.nodes}\n",
    "\n",
    "diamond_layout = {\n",
    "    n: (pos / 10 / np.cos(-np.pi / 4) - np.array([1, 0]))\n",
    "    for n, pos in diamond_layout.items()\n",
    "}\n",
    "\n",
    "G2_model_graph = GraphGP(\n",
    "    G2,\n",
    "    \"observation\",\n",
    "    nu=2.5,\n",
    ")\n",
    "G2_model_graph.fit()\n",
    "G2_model_graph.predict(G2)\n",
    "\n",
    "ax = axs[0]\n",
    "grid_plot(\n",
    "    G2,\n",
    "    \"prediction_mean\",\n",
    "    \"prediction_std\",\n",
    "    pos=diamond_layout,\n",
    "    node_size=50,\n",
    "    ax=ax,\n",
    "    **plot_kwargs_2D,\n",
    ")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_title(\"Graph GP Predictions\\nGrid Layout\")\n",
    "\n",
    "G2_model_spatial = SpatialGP(\n",
    "    G2,\n",
    "    \"observation\",\n",
    "    nu=2.5,\n",
    ")\n",
    "G2_model_spatial.fit()\n",
    "G2_model_spatial.predict(G2)\n",
    "\n",
    "ax = axs[1]\n",
    "grid_plot(\n",
    "    G2,\n",
    "    \"prediction_mean\",\n",
    "    \"prediction_std\",\n",
    "    pos=diamond_layout,\n",
    "    node_size=50,\n",
    "    ax=ax,\n",
    "    **plot_kwargs_2D,\n",
    ")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_title(\"Spatial GP Predictions\\nGrid Layout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To help explain why we see different behavior near the edges of the graph when we consider it as a true graph rather than as an image, let's plot the predictions in a more natural space for each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spectral_layout = nx.spectral_layout(G2)\n",
    "spectral_layout = {\n",
    "    n: (-pos[0], -pos[1]) for n, pos in spectral_layout.items()\n",
    "}  # Flip to match orientation of diamond layout\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "G2_model_graph.predict(G2)\n",
    "ax = axs[0]\n",
    "grid_plot(\n",
    "    G2,\n",
    "    \"prediction_mean\",\n",
    "    vmin=-1,\n",
    "    vmax=+1,\n",
    "    pos=spectral_layout,\n",
    "    ax=ax,\n",
    "    node_size=50,\n",
    ")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_title(\"Graph GP Mean\\nwith Spectral Layout\")\n",
    "\n",
    "G2_model_spatial.predict(G2)\n",
    "ax = axs[1]\n",
    "grid_plot(\n",
    "    G2,\n",
    "    \"prediction_mean\",\n",
    "    # \"prediction_std\",\n",
    "    vmin=-1,\n",
    "    vmax=+1,\n",
    "    pos=diamond_layout,\n",
    "    ax=ax,\n",
    "    node_size=50,\n",
    ")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_title(\"Spatial GP Mean\\nwith Grid Layout\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we've plotted the SpatialGP predictions with nodes positioned according to adjacency (that is, \"image-like\" Euclidean space, albeit rotated), but the GraphGP predictions have been plotted with the nodes positioned according to the first two (non-trivial) eigenvectors of the graph. These eigenvectors define the orientations which capture the most and second-most variation in *connectivity* (both adjacency and degree) between all nodes in the graph. In the middle of the graph, there isn't much variation, so the node positioning (and the \"propagation\" of the observations), looks similar to Euclidean space. Near the edges and especially near the corners, however, there is significant variation between neighbors in the connectivity of the nodes, causing the edge nodes to be \"squished\" towards the middle.\n",
    "\n",
    "Now we can start to see why the GraphGP behaves a bit differently. The GraphGP operates in *eigenspace* rather than Euclidean space. That is, the GP kernel is defined on the eigenvalues and eigenvectors of the graph's Laplacian. Predictions for nodes on the periphery are more similar to adjacent nodes than are nodes towards the middle because peripheral nodes are actually *closer* to their neighbors *in eigenspace*!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's look closer at the variance behavior, which also differs from the SpatialGP treatment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "soc = nx.second_order_centrality(G2)\n",
    "\n",
    "edge_values = {}\n",
    "for u, v in G2.edges:\n",
    "    G2.edges[u, v][\"delta_soc\"] = np.abs(soc[u] - soc[v])\n",
    "\n",
    "# Get initial positions from diamond_layout\n",
    "init_pos = {n: np.array(pos) for n, pos in diamond_layout.items()}\n",
    "\n",
    "# Prepare edge list and target lengths\n",
    "edges = list(G2.edges)\n",
    "target_lengths = np.array(list(nx.get_edge_attributes(G2, \"delta_soc\").values()))\n",
    "\n",
    "# Normalize target lengths for better scaling (optional)\n",
    "if np.max(target_lengths) > 0:\n",
    "    target_lengths = target_lengths / np.max(target_lengths)\n",
    "\n",
    "# Flatten initial positions for optimization\n",
    "nodes = list(G2.nodes)\n",
    "node_idx = {n: i for i, n in enumerate(nodes)}\n",
    "x0 = np.concatenate([init_pos[n] for n in nodes])\n",
    "\n",
    "\n",
    "def stress(x):\n",
    "    coords = x.reshape(-1, 2)\n",
    "    s = 0.0\n",
    "    for idx, (u, v) in enumerate(edges):\n",
    "        i, j = node_idx[u], node_idx[v]\n",
    "        dist = np.linalg.norm(coords[i] - coords[j])\n",
    "        s += (dist - target_lengths[idx]) ** 2\n",
    "    return s\n",
    "\n",
    "\n",
    "res = minimize(stress, x0, method=\"L-BFGS-B\")\n",
    "soc_layout = {n: res.x[2 * i : 2 * i + 2] for i, n in enumerate(nodes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(8, 4))\n",
    "\n",
    "G2_model_graph.predict(G2)\n",
    "ax = axs[0]\n",
    "grid_plot(\n",
    "    G2,\n",
    "    # \"prediction_mean\",\n",
    "    \"prediction_std\",\n",
    "    cmap=\"binary_r\",\n",
    "    vmin=0.4,\n",
    "    vmax=1.6,\n",
    "    pos=soc_layout,\n",
    "    ax=ax,\n",
    "    node_size=50,\n",
    ")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_title(\"Graph GP Uncertainty\\nwith SOC Layout\")\n",
    "\n",
    "G2_model_spatial.predict(G2)\n",
    "ax = axs[1]\n",
    "grid_plot(\n",
    "    G2,\n",
    "    # \"prediction_mean\",\n",
    "    \"prediction_std\",\n",
    "    cmap=\"binary_r\",\n",
    "    vmin=0.4,\n",
    "    vmax=1.6,\n",
    "    pos=diamond_layout,\n",
    "    ax=ax,\n",
    "    node_size=50,\n",
    ")\n",
    "ax.set_aspect(\"equal\")\n",
    "ax.set_title(\"Spatial GP Uncertainty\\nwith Grid Layout\")\n",
    "plt.colorbar(\n",
    "    plt.cm.ScalarMappable(\n",
    "        cmap=\"binary_r\",\n",
    "        norm=plt.Normalize(vmin=0.4, vmax=1.6),\n",
    "    ),\n",
    "    ax=ax,\n",
    "    label=\"Uncertainty\",\n",
    "    orientation=\"vertical\",\n",
    "    fraction=0.046,\n",
    "    pad=0.04,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the SpatialGP, the predictive uncertainty behavior of GraphGP varies near the periphery for the GraphGP, increasing sharply for corner nodes. In the plots above, this is visualized as an increase in paleness near the corners. As noted in the [GeometricKernels documentation](https://geometric-kernels.github.io/GeometricKernels/examples/backends/PyTorch_Graph.html#A-Note-on-Prior-Variance) and their [tutorial notebook](https://github.com/spbu-math-cs/Graph-Gaussian-Processes/blob/main/examples/graph_variance.ipynb), this comes from the variation in *expected return time* of a random walk over the nodes of graph. The corners are more \"difficult\" to get to on a random walk because there are fewer possible paths to them. This leads to a wide range of return times (short, via the immediate neighbors, and long, via the opposite corners) and so the uncertainty of predictions on these nodes is higher.\n",
    "\n",
    "Above, we visualize this discrepency by assigning the edge lengths on the Graph GP prediction to be the difference in *second-order centrality* (SOC) of the adjacent nodes. SOC provides the standard deviation in expected return times to the respective node. As we can see, nodes which are similar in SOC have similar predictive variances, with the corners having both the highest predictive variance and the biggest difference in SOC compared to their neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 4, figsize=(16, 12), sharex=True, sharey=\"row\")\n",
    "\n",
    "# Prepare a \"continuous\" grid for the spatial GP (like G1_)\n",
    "G2_dense = nx.grid_2d_graph(1, 101)\n",
    "old2new_G2 = {(0, j): (8, j / 10) for (_, j) in G2_dense.nodes}\n",
    "G2_dense = nx.relabel_nodes(G2_dense, old2new_G2)\n",
    "G2_model_spatial.predict(G2_dense)\n",
    "\n",
    "for col, nu in zip(axs.T, [0.5, 1.5, 2.5, np.inf]):\n",
    "    nu_str = \"∞\" if nu == np.inf else f\"{int(nu * 2)}/2\"\n",
    "\n",
    "    # Graph GP\n",
    "    graph_ax = col[0]\n",
    "    graph_ax.set_title(f\"Graph GP (nu={nu_str})\")\n",
    "    G2_model_graph = GraphGP(\n",
    "        G2,\n",
    "        \"observation\",\n",
    "        normalize_laplacian=False,\n",
    "        nu=nu,\n",
    "        trainable_nu=False,\n",
    "        scale_prior=(2.0, 0.15),\n",
    "        noise_prior=(1.1, 0.05),\n",
    "        noise_min=1e-8,\n",
    "    )\n",
    "    G2_model_graph.fit()\n",
    "    graph_preds = G2_model_graph.predict(G2)\n",
    "    grid_plot(G2, \"prediction_mean\", \"prediction_std\", ax=graph_ax, umin=0.4, umax=1.6)\n",
    "    # print(f\"Fitted Graph GP with nu={nu}:\",\n",
    "    #       G2_model_graph.model.get_parameter('covar_module.base_kernel.raw_nu').item())\n",
    "    graph_ax.set_aspect(\"equal\")\n",
    "\n",
    "    # Spatial GP\n",
    "    spat_ax = col[1]\n",
    "    spat_ax.set_title(f\"Spatial GP (nu={nu_str})\")\n",
    "    G2_model_spatial = SpatialGP(\n",
    "        G2,\n",
    "        \"observation\",\n",
    "        normalize_laplacian=False,\n",
    "        nu=nu,\n",
    "        scale_prior=(2.0, 0.15),\n",
    "        noise_prior=(1.1, 0.05),\n",
    "        noise_min=1e-8,\n",
    "    )\n",
    "    G2_model_spatial.fit()\n",
    "    G2_model_spatial.predict(G2)\n",
    "    grid_plot(G2, \"prediction_mean\", \"prediction_std\", ax=spat_ax, umin=0.4, umax=1.6)\n",
    "    spat_ax.set_aspect(\"equal\")\n",
    "\n",
    "    # 1D slice through row 9\n",
    "    slice_ax = col[2]\n",
    "    slice_ax.set_title(f\"Row 9 slice (nu={nu_str})\")\n",
    "    # Graph GP predictions for row 9\n",
    "    row9_nodes = [(8, j) for j in range(11)]\n",
    "    row9_x = [j for j in range(11)]\n",
    "    row9_mean = [graph_preds[node][\"prediction_mean\"] for node in row9_nodes]\n",
    "    row9_std = [graph_preds[node][\"prediction_std\"] for node in row9_nodes]\n",
    "    slice_ax.errorbar(\n",
    "        row9_x,\n",
    "        row9_mean,\n",
    "        yerr=2 * np.array(row9_std),\n",
    "        fmt=\"o\",\n",
    "        label=\"Graph GP μ±2σ\",\n",
    "        color=\"C1\",\n",
    "    )\n",
    "\n",
    "    # Spatial GP predictions for dense slice\n",
    "    G2_model_spatial.predict(G2_dense)\n",
    "    dense_x = [node[1] for node in G2_dense.nodes]\n",
    "    dense_mean = [G2_dense.nodes[node][\"prediction_mean\"] for node in G2_dense.nodes]\n",
    "    dense_std = [G2_dense.nodes[node][\"prediction_std\"] for node in G2_dense.nodes]\n",
    "    slice_ax.plot(dense_x, dense_mean, label=\"Spatial GP mean\", color=\"C0\")\n",
    "    slice_ax.fill_between(\n",
    "        dense_x,\n",
    "        np.array(dense_mean) - 2 * np.array(dense_std),\n",
    "        np.array(dense_mean) + 2 * np.array(dense_std),\n",
    "        alpha=0.2,\n",
    "        color=\"C0\",\n",
    "        label=\"Spatial GP ±2σ\",\n",
    "    )\n",
    "\n",
    "    # Observations in row 9\n",
    "    obs = nx.get_node_attributes(G2, \"observation\")\n",
    "    obs_x = [j for (i, j) in obs if i == 8]\n",
    "    obs_y = [obs[(8, j)] for j in obs_x]\n",
    "    if obs_x:\n",
    "        slice_ax.scatter(obs_x, obs_y, color=\"black\", label=\"Observations\", zorder=5)\n",
    "\n",
    "    slice_ax.set_xlabel(\"Column (j)\")\n",
    "    slice_ax.set_ylabel(\"Prediction\")\n",
    "    # slice_ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
